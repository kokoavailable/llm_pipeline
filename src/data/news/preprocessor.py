import re
import logging
from bs4 import BeautifulSoup
import pandas as pd
import os
from konlpy.tag import Okt

from utils.helpers import logger
from utils.stopwords_kr import stopwords
class NewsPreprocessor:
    """í¬ë¡¤ë§í•œ raw ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self):
        """ë‰´ìŠ¤ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        self.okt = Okt()
        self.stopwords = stopwords
        pass

    def remove_stopwords(self, text):
        tokens = self.okt.morphs(text)
        filtered = [word for word in tokens if word not in self.stopwords]
        return ' '.join(filtered)

    def clean_text(self, text):
        """
        í…ìŠ¤íŠ¸ ì •ì œ
        
        Args:
            text (str): ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            str: ì •ì œëœ í…ìŠ¤íŠ¸
        """
        if not isinstance(text, str):
            return ""
            
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<.*?>', '', text)
        
        # íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
        text = re.sub(r'[^\w\s\.]', ' ', text)
        
        # ì—¬ëŸ¬ ê°œì˜ ê³µë°±ì„ í•˜ë‚˜ë¡œ í†µí•©
        text = re.sub(r'\s+', ' ', text)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        return text

    def process_dataframe(self, df):
        """
        ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬
        
        Args:
            df (pd.DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„
            
        Returns:
            pd.DataFrame: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        """
        logger.info("ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬ ì‹œì‘")
        
        # ë³µì‚¬ë³¸ ìƒì„±
        processed_df = df.copy()
        
        # ì¤‘ë³µ ì œê±°
        before = len(processed_df)
        processed_df.drop_duplicates(subset=['title', 'content'], inplace=True)
        after = len(processed_df)
        logger.info(f"ğŸ§¹ ì¤‘ë³µ ì œê±°: {before - after}ê°œ ì œê±° â†’ {after}ê°œ ë‚¨ìŒ")

        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        processed_df['title'] = processed_df['title'].fillna('')
        processed_df['content'] = processed_df['content'].fillna('')
        
        # í…ìŠ¤íŠ¸ ì •ì œ
        processed_df['title_clean'] = processed_df['title'].apply(self.clean_text)
        processed_df['content_clean'] = processed_df['content'].apply(self.clean_text)
        
        # ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ì€ ê¸°ì‚¬ í•„í„°ë§
        before = len(processed_df)
        processed_df = processed_df[processed_df['content_clean'].str.len() > 50]
        after = len(processed_df)
        logger.info(f"50ì ì´í•˜ ê¸°ì‚¬ ì œê±°: {before - after}ê°œ ì œê±° â†’ {after}ê°œ ë‚¨ìŒ")

        # ë¶ˆìš©ì–´ ì œê±° (content_clean ê¸°ì¤€)
        processed_df['content_nostop'] = processed_df['content_clean'].apply(self.remove_stopwords)


        # ë‚ ì§œ í˜•ì‹ í†µì¼
        try:
            processed_df['date'] = pd.to_datetime(processed_df['date'])
            processed_df = processed_df.sort_values(by='date')
            processed_df['date'] = processed_df['date'].dt.strftime('%Y-%m-%d')
        except:
            logger.warning("ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì˜¤ë¥˜, ì›ë³¸ ìœ ì§€")
        
        # ê³ ìœ  ID ìƒì„±
        processed_df['article_id'] = [
            f"{src}_{i}" for i, src in enumerate(processed_df['source'])
        ]
        
        logger.info(f"ì „ì²˜ë¦¬ ì™„ë£Œ: {len(processed_df)}ê°œ ê¸°ì‚¬")
        return processed_df
    
    def process_file(self, input_path, output_path):
        """
        íŒŒì¼ ì²˜ë¦¬
        
        Args:
            input_path (str): ì…ë ¥ íŒŒì¼ ê²½ë¡œ
            output_path (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            pd.DataFrame: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        """
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(input_path):
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {input_path}")
            return None
        
            

        df = pd.read_csv(input_path)
            
        # ì „ì²˜ë¦¬
        processed_df = self.process_dataframe(df)
        
        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        # ì €ì¥
        processed_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        json_path = output_path.replace('.csv', '.json')

        processed_df.to_json(json_path, orient='records', force_ascii=False, indent=4)
        
        logger.info(f"ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path}")
        return processed_df
    
    def run(self, input_path='data/raw/news_articles.csv', output_path='data/processed/processed_news.csv'):
        """
        ì „ì²˜ë¦¬ ì‹¤í–‰
        
        Args:
            input_path (str): ì…ë ¥ íŒŒì¼ ê²½ë¡œ
            output_path (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            pd.DataFrame: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        """
        return self.process_file(input_path, output_path)